{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Musical Note Classifier\n",
        "Dongim Lee, Sally Lee, Zara Coakley\n",
        "\n",
        "### A CNN model that can detect the pitch and length of a single note on a staff\n",
        "\n",
        "This notebook contains a walkthrough of using our code to generate note data, augement the data, and train our CNN model on that data."
      ],
      "metadata": {
        "id": "DgR7KOHQwsCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generation\n",
        "\n",
        "We used Music21 to generate our note data. To use this part of the code you will need to download LilyPond: https://lilypond.org/doc/v2.23/Documentation/web/download\n",
        "\n",
        "This code generates 1,785 images of notes ranging from A3 to C6. The possible lengths are whole, half, quarter, eighth, sixteenth. To add variation into the model, it also generates distracting symbols, including sharps, flats, and dots. Notably, our model itself doesn't take these symbols into account. It does not differentiate between G, G sharp, and G flat but instead calls them all G. It also doesn't take into account dotted notes when classifying length."
      ],
      "metadata": {
        "id": "gWAajqWAw5-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Generate single music notes\"\"\"\n",
        "\n",
        "import os\n",
        "from music21 import note, stream\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def generate_note_image_with_variations(\n",
        "    pitch, name, note_length, filename, variations, beams=False\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate an image of a single note with variations and crop it.\n",
        "    :param pitch: Pitch of the note (e.g., 'C4', 'D#5')\n",
        "    :param note_length: Length of the note ('whole', 'half', 'quarter', etc.)\n",
        "    :param filename: Output filename for the image\n",
        "    :param variations: Dict containing variations (dynamics, articulation, accidental, fermata)\n",
        "    :param beams: Flag to include/exclude beams\n",
        "    \"\"\"\n",
        "    s = stream.Stream()\n",
        "\n",
        "    if name in [\"eighth\", \"16th\"] and beams:\n",
        "        # Add connected notes (beams)\n",
        "        n1 = note.Note(pitch, quarterLength=note_length)\n",
        "        n2 = note.Note(pitch, quarterLength=note_length)  # Another note for the beam\n",
        "        n1.beams.fill(name, type=\"start\")  # Start beam\n",
        "        n2.beams.fill(name, type=\"stop\")  # Stop beam\n",
        "\n",
        "        # Apply variations\n",
        "        if variations.get(\"accidental\"):\n",
        "            n1.pitch.accidental = variations[\"accidental\"]\n",
        "        if variations.get(\"articulation\"):\n",
        "            n1.articulations.append(variations[\"articulation\"])\n",
        "        s.append([n1, n2])\n",
        "\n",
        "    else:\n",
        "        # Add a single note\n",
        "        n = note.Note(pitch)\n",
        "        n.quarterLength = note_length\n",
        "\n",
        "        # Apply variations\n",
        "        if variations.get(\"accidental\"):\n",
        "            n.pitch.accidental = variations[\"accidental\"]\n",
        "        if variations.get(\"articulation\"):\n",
        "            n.articulations.append(variations[\"articulation\"])\n",
        "        s.append(n)\n",
        "\n",
        "    # Save to PNG\n",
        "    temp_filename = os.path.join(\"temp\", filename)\n",
        "    s.write(\"lily.png\", fp=temp_filename)\n",
        "\n",
        "    # Crop the image to focus on the note\n",
        "    # crop_note(f\"{temp_filename}.png\", os.path.join(\"data\", f\"{filename}.png\"))\n",
        "\n",
        "\n",
        "def crop_note(input_filename, output_filename):\n",
        "    \"\"\"\n",
        "    Crop the generated note image to focus on the relevant area.\n",
        "    :param input_filename: Full-sized image filename\n",
        "    :param output_filename: Cropped image filename\n",
        "    \"\"\"\n",
        "    with Image.open(input_filename) as img:\n",
        "        left, top, right, bottom = 120, 15, 150, 70  # Adjust based on staff size\n",
        "        cropped_img = img.crop((left, top, right, bottom))\n",
        "        cropped_img.save(output_filename)\n",
        "        print(f\"Cropped and saved {output_filename}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    os.makedirs(\"temp\", exist_ok=True)\n",
        "    # os.makedirs(\"data\", exist_ok=True)\n",
        "    pitches = [\n",
        "        \"A3\",\n",
        "        \"B3\",\n",
        "        \"C4\",\n",
        "        \"D4\",\n",
        "        \"E4\",\n",
        "        \"F4\",\n",
        "        \"G4\",\n",
        "        \"A4\",\n",
        "        \"B4\",\n",
        "        \"C5\",\n",
        "        \"D5\",\n",
        "        \"E5\",\n",
        "        \"F5\",\n",
        "        \"G5\",\n",
        "        \"A5\",\n",
        "        \"B5\",\n",
        "        \"C6\",\n",
        "    ]  # Example pitches\n",
        "    lengths = {\n",
        "        \"whole\": 4.0,\n",
        "        \"half\": 2.0,\n",
        "        \"quarter\": 1.0,\n",
        "        \"eighth\": 0.5,\n",
        "        \"16th\": 0.25,\n",
        "    }  # Note lengths\n",
        "\n",
        "    # Define all variations\n",
        "    articulation_variations = [None]\n",
        "    accidental_variations = [None, \"sharp\", \"flat\"]\n",
        "    is_beams = [True, False]\n",
        "\n",
        "    # Generate combinations of variations\n",
        "    for pitch in pitches:\n",
        "        for length, length_num in lengths.items():\n",
        "            VARIATION_ID = 0\n",
        "            for art in articulation_variations:\n",
        "                for acc in accidental_variations:\n",
        "                    variations = {\n",
        "                        \"articulation\": art,\n",
        "                        \"accidental\": acc,\n",
        "                    }\n",
        "                    filename = f\"note_{pitch}_{length}_variation_{VARIATION_ID}\"\n",
        "                    generate_note_image_with_variations(\n",
        "                        pitch, length, length_num, filename, variations\n",
        "                    )\n",
        "                    VARIATION_ID += 1\n",
        "                    if length in [\"eighth\", \"16th\"]:\n",
        "                        filename = f\"note_{pitch}_{length}_variation_{VARIATION_ID}\"\n",
        "                        generate_note_image_with_variations(\n",
        "                            pitch, length, length_num, filename, variations, beams=True\n",
        "                        )\n",
        "                        VARIATION_ID += 1"
      ],
      "metadata": {
        "id": "fj92d3_8w5O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Augmentation\n",
        "\n",
        "We then augmented the generated note data to add more variation to our dataset. If you generated raw data using the code above, use these functions to augment the data. If you're just using the dataset from the github/huggingface (https://huggingface.co/dongim04/musical-note-classifier), you don't need to do this.\n",
        "\n",
        "Augmentations:\n",
        "- random cropping\n",
        "- rotation by up to three degrees\n",
        "- shearing\n",
        "- zooming\n",
        "- flipping horizontally"
      ],
      "metadata": {
        "id": "-d1Y4SOqxjIg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtQP-MnfwZu-"
      },
      "outputs": [],
      "source": [
        "\"\"\"Augment original data by cropping in different places\"\"\"\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def crop_note_with_variation(input_filename, output_filename, crop_id=0):\n",
        "    \"\"\"\n",
        "    Crop the generated note image to focus on the relevant area.\n",
        "    :param input_filename: Full-sized image filename\n",
        "    :param output_filename: Cropped image filename\n",
        "    \"\"\"\n",
        "    with Image.open(input_filename) as img:\n",
        "        if crop_id == 0:\n",
        "            left, top, right, bottom = 115, 10, 155, 50  # Adjust based on staff size\n",
        "        elif crop_id == 1:\n",
        "            left, top, right, bottom = 115, 5, 155, 45  # up\n",
        "        elif crop_id == 2:\n",
        "            left, top, right, bottom = 115, 15, 155, 55  # down\n",
        "        elif crop_id == 3:\n",
        "            left, top, right, bottom = 110, 10, 150, 50  # left\n",
        "        else:\n",
        "            left, top, right, bottom = 120, 10, 160, 50  # right\n",
        "        cropped_img = img.crop((left, top, right, bottom))\n",
        "        cropped_img.save(output_filename)\n",
        "        print(f\"Cropped and saved {output_filename}\")\n",
        "\n",
        "def augment_data(input_foldername, output_foldername):\n",
        "    file_names = os.listdir(input_foldername)\n",
        "\n",
        "    pitch_labels = []\n",
        "    length_labels = []\n",
        "\n",
        "    for file_name in file_names:\n",
        "        pitch_labels.append(file_name[5:7])\n",
        "        length_labels.append(file_name[8:-18])\n",
        "\n",
        "    file_names = np.char.add(input_foldername, file_names)\n",
        "    file_names = np.array(file_names)\n",
        "    pitch_labels = np.array(pitch_labels)\n",
        "    length_labels = np.array(length_labels)\n",
        "\n",
        "    images = []\n",
        "\n",
        "    for path in tqdm(file_names, desc=\"Processing images\"):\n",
        "        try:\n",
        "            image = Image.open(path)\n",
        "            image = image.convert('L')  # 'L' for grayscale\n",
        "            image = image.resize((64, 64))\n",
        "            image_array = np.array(image) / 255.0\n",
        "            images.append(image_array)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {path}: {e}\")\n",
        "\n",
        "    images = np.array(images)\n",
        "\n",
        "    num_pitch_classes = len(set(pitch_labels))  # (A3 to C6)\n",
        "    num_length_classes = len(set(length_labels))  # (whole, half, quarter, eighth, 16th)\n",
        "    num_classes = num_pitch_classes * num_length_classes\n",
        "\n",
        "    images = np.expand_dims(images, axis=-1)  # Shape: (n, 64, 64, 1)\n",
        "\n",
        "    combined_labels = [p + l for p, l in zip(pitch_labels, length_labels)]\n",
        "    encoder = LabelEncoder()\n",
        "    combined_labels_encoded = encoder.fit_transform(combined_labels)\n",
        "\n",
        "    labels = to_categorical(combined_labels_encoded, num_classes=num_classes) # Shape: (n, num_classes)\n",
        "\n",
        "    augmented_augmented_data_dir = output_foldername\n",
        "    os.makedirs(augmented_augmented_data_dir, exist_ok=True)\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=3,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode=\"nearest\"\n",
        "    )\n",
        "\n",
        "    augmentations_per_image = 30\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    # Generate augmented images\n",
        "    for i, (image, label) in enumerate(zip(images, labels)):\n",
        "        for batch in datagen.flow(\n",
        "            np.expand_dims(image, axis=0),  # Shape: (1, 64, 64, 1)\n",
        "            batch_size=1,\n",
        "            save_to_dir=augmented_augmented_data_dir,\n",
        "            save_prefix=f\"{file_names[i][67:-4]}\",\n",
        "            save_format=\"png\"\n",
        "        ):\n",
        "            augmented_images.append(batch[0])\n",
        "            augmented_labels.append(label)\n",
        "\n",
        "            if len(augmented_images) % augmentations_per_image == 0:\n",
        "                break\n",
        "\n",
        "    all_images = np.concatenate((images, np.array(augmented_images)), axis=0)\n",
        "    all_labels = np.concatenate((labels, np.array(augmented_labels)), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined Pitch and Length Model\n",
        "\n",
        "Next, we defined our model architecture and parameters and trained our model on the dataset.\n",
        "\n",
        " If you download the dataset from the github/huggingface you can start running the code here. You don't have to do any of the augmentation."
      ],
      "metadata": {
        "id": "xfR0osOUyPvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, import necessary libraries."
      ],
      "metadata": {
        "id": "f8_PAbDNzzra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Input, Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm  # for progress bar"
      ],
      "metadata": {
        "id": "4XEe_l4tyY2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into train and test images."
      ],
      "metadata": {
        "id": "rcS-Ob200_Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
        "    all_images, all_labels, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "    temp_images, temp_labels, test_size=0.5, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "6E5c1KLh1D4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model architecture."
      ],
      "metadata": {
        "id": "fbFsivEt1Gxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_advanced_cnn_model_with_l2(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Attention Mechanism (SE Block)\n",
        "    se = layers.GlobalAveragePooling2D()(x)\n",
        "    se = layers.Dense(128 // 16, activation='relu', kernel_regularizer=l2(0.001))(se)  # Bottleneck\n",
        "    se = layers.Dense(128, activation='sigmoid', kernel_regularizer=l2(0.001))(se)\n",
        "    x = layers.multiply([x, se])  # Scale the feature maps\n",
        "\n",
        "    # Block 4\n",
        "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Dropout(0.25)(x)\n",
        "\n",
        "    # Global Average Pooling and Fully Connected Layers\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.001), name='output')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ieArRoh91E3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks: early stopping and L2 regularization to prevent overfitting."
      ],
      "metadata": {
        "id": "NG5TYKd91Szc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "bBOdOr8H1SMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the model."
      ],
      "metadata": {
        "id": "11cfXsVQ1WbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (64, 64, 1)\n",
        "model = create_advanced_cnn_model_with_l2(input_shape, num_classes) # create_advanced_cnn_model_with_l2\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZBxfazc51V3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model."
      ],
      "metadata": {
        "id": "MQwG-GDA1ZbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = datagen.flow(train_images, train_labels, batch_size=32)\n",
        "val_generator = (val_images, val_labels)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=500,\n",
        "    callbacks=[early_stopping, lr_scheduler] # lr_scheduler\n",
        ")"
      ],
      "metadata": {
        "id": "OIm7SWahjWOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot losses."
      ],
      "metadata": {
        "id": "qnE6gvq-1gut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GtcqqF7l1cla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model."
      ],
      "metadata": {
        "id": "gZQ8AvyR1uB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=1)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "La__qCJW1rx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate metrics. If you would like to actually see the metrics from our model, visit our website! https://musical-note-classifier.onrender.com/ (It might take 15 sec or so to load)"
      ],
      "metadata": {
        "id": "uRlxCzkq3ySY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "# Evaluate the model and get predictions\n",
        "# test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=1)\n",
        "predicted_probs = model.predict(test_images)\n",
        "predicted_classes = np.argmax(predicted_probs, axis=1)\n",
        "true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Compute additional metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_classes, predicted_classes, digits=4))\n",
        "\n",
        "# Optionally, calculate and print additional individual metrics\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "id": "B23FQkvC3xdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Model\n",
        "\n",
        "If you would like to import the model instead of training it yourself, use the code below."
      ],
      "metadata": {
        "id": "Dxcpc09P12Wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, download the model and encoder from our github and upload them here."
      ],
      "metadata": {
        "id": "ntPZycFP2GjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model and encoder."
      ],
      "metadata": {
        "id": "iu9sSM202wis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "model = tf.keras.models.load_model('path/to/the/model_weights.h5')\n",
        "\n",
        "with open('path/to/the/encoder.pkl', 'rb') as file:\n",
        "    encoder = pickle.load(file)"
      ],
      "metadata": {
        "id": "tICfWKXE1_D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the model on your images."
      ],
      "metadata": {
        "id": "aVvYCqvt5EMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "examples_folder = 'folder containing the images you want to test the model on'\n",
        "\n",
        "for file_name in os.listdir(examples_folder):\n",
        "    file_path = os.path.join(examples_folder, file_name)\n",
        "\n",
        "    image = Image.open(file_path)\n",
        "    image_array = np.array(image.convert('L').resize((64, 64))) / 255.0\n",
        "    image_array = np.expand_dims(image_array, axis=0)  # Shape becomes (1, 64, 64)\n",
        "    image_array = np.expand_dims(image_array, axis=-1)  # Shape becomes (1, 64, 64, 1)\n",
        "\n",
        "    predictions = model.predict(image_array)\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    predicted_label = encoder.inverse_transform([predicted_class_index])\n",
        "    confidence = predictions[0][predicted_class_index]\n",
        "\n",
        "    print(f\"Actual label: {file_name[:-4]}\")\n",
        "    print(f\"Predicted label: {predicted_label[0]}\")\n",
        "    print(f\"Confidence: {confidence:.2f}\")\n",
        "    print('-' * 40)"
      ],
      "metadata": {
        "id": "KgUv37CZ2gpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate a summary of the model"
      ],
      "metadata": {
        "id": "sEDDx6tqCWFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important characteristics:\n",
        "- 696,255 parameters\n",
        "- Dropout layers (25%)\n",
        "- ReLU activatation\n",
        "- Batch normalization\n",
        "- Max pooling\n",
        "- L2 regularization\n",
        "- Early stopping and learning rate scheduler"
      ],
      "metadata": {
        "id": "AXPTRLs9xnYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UdnkITsAxQi1",
        "outputId": "232eddc1-0c18-4fd7-a50a-c777ef88fcf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_21\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_21\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_21            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_147 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m320\u001b[0m │ input_layer_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_147   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_147[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_148 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │          \u001b[38;5;34m9,248\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_148   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_148[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_84          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_126 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_149 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m18,496\u001b[0m │ dropout_126[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_149   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_149[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_150 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m36,928\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_150   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m256\u001b[0m │ conv2d_150[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_85          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_127 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_151 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m73,856\u001b[0m │ dropout_127[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_151   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_151[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_152 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m147,584\u001b[0m │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_152   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_152[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_86          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_128 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │          \u001b[38;5;34m1,032\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │          \u001b[38;5;34m1,152\u001b[0m │ dense_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_21 (\u001b[38;5;33mMultiply\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ dropout_128[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │                        │                │ dense_85[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_153 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m295,168\u001b[0m │ multiply_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_153   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_153[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_87          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_129 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ max_pooling2d_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_129[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m65,792\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_130 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_86[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout_130[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_131 (\u001b[38;5;33mDropout\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_87[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)             │         \u001b[38;5;34m10,965\u001b[0m │ dropout_131[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_21            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_147 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ input_layer_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_147   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_147[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_148 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_148   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_148[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_84          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_126 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_149 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ dropout_126[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_149   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_149[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_150 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_150   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_150[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_85          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_127 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_151 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_127[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_151   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_151[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_152 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_152   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_152[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_86          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │ dense_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multiply_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_128[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │                        │                │ dense_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_153 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ multiply_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_153   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_153[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ max_pooling2d_87          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)            │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_129 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_129[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_130 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_130[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_87[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">10,965</span> │ dropout_131[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m696,255\u001b[0m (2.66 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">696,255</span> (2.66 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m694,845\u001b[0m (2.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">694,845</span> (2.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,408\u001b[0m (5.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> (5.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}